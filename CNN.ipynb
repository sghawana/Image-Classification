{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3MbdV3Rn4ca"
      },
      "source": [
        "# **Convolutional Neural Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXPPqjKR0RzU"
      },
      "source": [
        "### Importing necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QTFF0ahoEac"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ytlfoWf5kri"
      },
      "source": [
        "### Importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcOridjgBcED"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "def unpickle(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "do5J7L69CkzM"
      },
      "outputs": [],
      "source": [
        "train1 = unpickle('/content/data_batch_1')\n",
        "train2 = unpickle('/content/data_batch_2')\n",
        "train3 = unpickle('/content/data_batch_3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txj6jGkA0Zen"
      },
      "source": [
        "### Pre-processing training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQ0sJUE4LoPB"
      },
      "outputs": [],
      "source": [
        "x1 = train1[b'data']\n",
        "x2 = train2[b'data']\n",
        "x3 = train3[b'data']\n",
        "y1 = train1[b'labels']\n",
        "y2 = train2[b'labels']\n",
        "y3 = train3[b'labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5ABRVGLpP1X"
      },
      "outputs": [],
      "source": [
        "x1new = torch.from_numpy(x1)\n",
        "x1new = x1new.to(torch.float32)\n",
        "x1new = x1new.view(10000,3,32,32)\n",
        "\n",
        "x2new = torch.from_numpy(x2)\n",
        "x2new = x2new.to(torch.float32)\n",
        "x2new = x2new.view(10000,3,32,32)\n",
        "\n",
        "\n",
        "x3new = torch.from_numpy(x3)\n",
        "x3new = x3new.to(torch.float32)\n",
        "x3new = x3new.view(10000,3,32,32)\n",
        "\n",
        "train_data = torch.cat((x1new, x2new, x3new), dim=0)\n",
        "\n",
        "train_labels = y1 + y2 + y3\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awQqB-q10eFs"
      },
      "source": [
        "\n",
        "### Setting hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuyYHQGKjlkR"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "num_epochs = 15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_z-v91z7Qlf"
      },
      "source": [
        "### Train Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HicJhQx5GUbs"
      },
      "outputs": [],
      "source": [
        "train_dataset = []\n",
        "\n",
        "for i in range(len(train_labels)):\n",
        "  train_dataset.append((train_data[i],train_labels[i]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_KpyqM2GDRq"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRaEYJw-0h2T"
      },
      "source": [
        "### Building CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaiHRhGX29PT"
      },
      "source": [
        "### **MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhDZfhCNszS8"
      },
      "outputs": [],
      "source": [
        "class CNN1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN1, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=0)\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=0)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0)\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc4 = nn.Linear(5 * 5 * 64, 1600)\n",
        "        self.fc5 = nn.Linear(1600, 400)\n",
        "        self.fc6 = nn.Linear(400, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.sigmoid(self.conv1(x))\n",
        "        x = self.maxpool1(x)\n",
        "        x = F.sigmoid(self.conv2(x))\n",
        "        x = F.sigmoid(self.conv3(x))\n",
        "        x = self.maxpool3(x)\n",
        "        x = self.flatten(x)\n",
        "        x = F.sigmoid(self.fc4(x))\n",
        "        x = F.sigmoid(self.fc5(x))\n",
        "        x = self.fc6(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN2, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=0)\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=0)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0)\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc4 = nn.Linear(5 * 5 * 64, 1600)\n",
        "        self.fc5 = nn.Linear(1600, 400)\n",
        "        self.fc6 = nn.Linear(400, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.maxpool1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.maxpool3(x)\n",
        "        x = self.flatten(x)\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = F.relu(self.fc5(x))\n",
        "        x = self.fc6(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Q5DrFJdqpI87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeJnXaQqHHiu"
      },
      "source": [
        "Running an instance of CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gdsn52TLvJ_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df812d3a-1d5d-49fa-a876-ce6a91f7ba61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sigmoid Output: tensor([[-0.2790,  0.0953, -0.0477,  0.0945,  0.0440, -0.0810, -0.2689,  0.2865,\n",
            "         -0.0066,  0.1186]], grad_fn=<AddmmBackward0>)\n",
            "ReLU Output: tensor([[ 0.0532, -0.0375, -0.0219, -0.0349,  0.0336,  0.0135,  0.0312, -0.0309,\n",
            "          0.0086,  0.0374]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "model1  = CNN1()\n",
        "model2 = CNN2()\n",
        "\n",
        "#A random input image with batch size 1\n",
        "input_image = torch.rand(1,3,32,32)\n",
        "\n",
        "#Forward pass\n",
        "output1 = model1.forward(input_image)\n",
        "output2 = model2.forward(input_image)\n",
        "\n",
        "\n",
        "\n",
        "print(f'Sigmoid Output: {output1}')\n",
        "print(f'ReLU Output: {output2}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K9EtbQh0mnB"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waesO1SYgAAF"
      },
      "source": [
        "### **1. Sigmoid Activation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR22ma5yITV5"
      },
      "source": [
        "Define Loss Function and Optimiser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCjyUU2hISDC"
      },
      "outputs": [],
      "source": [
        "criterion1 = nn.CrossEntropyLoss()\n",
        "optimizer1 = torch.optim.Adam(model1.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtgqX49FIhkq"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ho3UdwKgiNR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eef85fb-a105-4a6e-f210-78594219fd43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch [1/15], Loss: 2.1265\n",
            "Epoch [2/15], Loss: 2.0678\n",
            "Epoch [3/15], Loss: 1.9776\n",
            "Epoch [4/15], Loss: 1.7438\n",
            "Epoch [5/15], Loss: 1.8236\n",
            "Epoch [6/15], Loss: 1.4628\n",
            "Epoch [7/15], Loss: 1.5577\n",
            "Epoch [8/15], Loss: 1.5133\n",
            "Epoch [9/15], Loss: 1.3139\n",
            "Epoch [10/15], Loss: 1.5585\n",
            "Epoch [11/15], Loss: 1.4993\n",
            "Epoch [12/15], Loss: 1.4073\n",
            "Epoch [13/15], Loss: 1.2176\n",
            "Epoch [14/15], Loss: 1.1968\n",
            "Epoch [15/15], Loss: 1.3070\n",
            "Training End\n"
          ]
        }
      ],
      "source": [
        "print(\"Training Start\")\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model1.forward(images)\n",
        "        loss1 = criterion1(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer1.zero_grad()\n",
        "        loss1.backward()\n",
        "        optimizer1.step()\n",
        "\n",
        "\n",
        "    print ('Epoch [{}/{}], Loss: {:.4f}'\n",
        "            .format(epoch+1, num_epochs,loss1.item()))\n",
        "print(\"Training End\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDgSpmWOgnn6"
      },
      "source": [
        "### **2. ReLU Activation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oB2iUshgyhS"
      },
      "source": [
        "Define Loss Function and Optimiser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YToLEtJg0Uk"
      },
      "outputs": [],
      "source": [
        "criterion2 = nn.CrossEntropyLoss()\n",
        "optimizer2 = torch.optim.Adam(model2.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHHYwKHJg6ic"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqD2xoIhg-kT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5eb9be1-fd21-4b8d-e942-914edf3eec43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Start\n",
            "Epoch [1/15], Loss: 1.3587\n",
            "Epoch [2/15], Loss: 1.4867\n",
            "Epoch [3/15], Loss: 1.2875\n",
            "Epoch [4/15], Loss: 1.0870\n",
            "Epoch [5/15], Loss: 0.9632\n",
            "Epoch [6/15], Loss: 0.9476\n",
            "Epoch [7/15], Loss: 0.7318\n",
            "Epoch [8/15], Loss: 0.5454\n",
            "Epoch [9/15], Loss: 0.5463\n",
            "Epoch [10/15], Loss: 0.5285\n",
            "Epoch [11/15], Loss: 0.3733\n",
            "Epoch [12/15], Loss: 0.4413\n",
            "Epoch [13/15], Loss: 0.2751\n",
            "Epoch [14/15], Loss: 0.2875\n",
            "Epoch [15/15], Loss: 0.2241\n",
            "Training End\n"
          ]
        }
      ],
      "source": [
        "print(\"Training Start\")\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model2.forward(images)\n",
        "        loss2 = criterion2(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer2.zero_grad()\n",
        "        loss2.backward()\n",
        "        optimizer2.step()\n",
        "\n",
        "\n",
        "    print ('Epoch [{}/{}], Loss: {:.4f}'\n",
        "            .format(epoch+1, num_epochs,loss2.item()))\n",
        "print(\"Training End\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhwxMhqV3T9F"
      },
      "source": [
        "###**Train Accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fi6nATGk3Qpe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94f4a943-77e1-468f-df90-4f0596f24494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training End\n",
            "Activation: Sigmoid \n",
            "Loss: 1.3070132732391357 \n",
            "Learning Rate: 0.001 \n",
            "Training Accuracy of the Sigmoid model on the 30000 images: 55.86333333333334 %\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in train_loader:\n",
        "\n",
        "        outputs = model1.forward(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    print(\"Training End\")\n",
        "    print(f\"Activation: Sigmoid \")\n",
        "    print(f\"Loss: {loss1.item()} \")\n",
        "    print(f\"Learning Rate: {learning_rate} \")\n",
        "    print('Training Accuracy of the Sigmoid model on the 30000 images: {} %'.format(100 * correct / total))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t28mdP5p3Sug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68e1d5b6-7e39-4852-c7dd-86902d761b54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training End\n",
            "Activation: ReLU\n",
            "Loss: 0.22406938672065735 \n",
            "Learning Rate: 0.001 \n",
            "Training Accuracy of the ReLU model on the 30000 images: 96.15333333333334 %\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in train_loader:\n",
        "\n",
        "        outputs = model2.forward(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(\"Training End\")\n",
        "    print(f\"Activation: ReLU\")\n",
        "    print(f\"Loss: {loss2.item()} \")\n",
        "    print(f\"Learning Rate: {learning_rate} \")\n",
        "    print('Training Accuracy of the ReLU model on the 30000 images: {} %'.format(100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mtFTJX2Jvoc"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOm7WfhWlK7W"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAMWU9bUqnG4"
      },
      "source": [
        "Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjgwNWE_pPGV"
      },
      "outputs": [],
      "source": [
        "test = unpickle('/content/test_batch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53DKrIDvlSNf"
      },
      "outputs": [],
      "source": [
        "xts = test[b'data']\n",
        "yts = test[b'labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mP5ZtYAnlU1y"
      },
      "outputs": [],
      "source": [
        "xts = torch.from_numpy(xts)\n",
        "xts = xts.to(torch.float32)\n",
        "xts = xts.view(10000,3,32,32)\n",
        "\n",
        "test_dataset = []\n",
        "\n",
        "for i in range(len(yts)):\n",
        "  test_dataset.append((xts[i],yts[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUq9dGjUlWAg"
      },
      "outputs": [],
      "source": [
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJpHLUbcqpX2"
      },
      "source": [
        "Additional Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oCfGOdkmDrZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "test_add = np.load('/content/test_additional.npy')\n",
        "labels_add = np.load('/content/labels.npy')\n",
        "test_add = torch.from_numpy(test_add).float()\n",
        "test_add = test_add.permute(0,3,1,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkkO-wwzpSsZ"
      },
      "outputs": [],
      "source": [
        "test_add_dataset = []\n",
        "\n",
        "for i in range(len(labels_add)):\n",
        "  temp = (test_add[i],float(labels_add[i]))\n",
        "  test_add_dataset.append(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojMvty0CqJNS"
      },
      "outputs": [],
      "source": [
        "test_add_loader = torch.utils.data.DataLoader(dataset=test_add_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQKjZ-WHll9z"
      },
      "source": [
        "### **1. Sigmoid Activation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_jBKqwgXy7F"
      },
      "source": [
        "### test_batch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbghXir5KKNA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6792d30-3972-4e43-b34e-4a09d0e11929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST BATCH\n",
            "Activation: Sigmoid\n",
            "Learning Rate: 0.001 \n",
            "Test Accuracy of the Sigmoid model on the 10000 test images: 52.43 %\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "\n",
        "        outputs = model1.forward(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(\"TEST BATCH\")\n",
        "    print(f\"Activation: Sigmoid\")\n",
        "    print(f\"Learning Rate: {learning_rate} \")\n",
        "    print('Test Accuracy of the Sigmoid model on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxypeMwPX3CD"
      },
      "source": [
        "###  test_additional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Wg36NBkw-oz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4a08d0a-0b3f-4485-903e-b0503686b7dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADDITIONAL TEST BATCH\n",
            "Activation: Sigmoid\n",
            "Learning Rate: 0.001 \n",
            "Test Accuracy of the Sigmoid model on the additional test images: 49.41 %\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_add_loader:\n",
        "\n",
        "        outputs = model1.forward(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(\"ADDITIONAL TEST BATCH\")\n",
        "    print(f\"Activation: Sigmoid\")\n",
        "    print(f\"Learning Rate: {learning_rate} \")\n",
        "    print('Test Accuracy of the Sigmoid model on the additional test images: {} %'.format(100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1HU9Enqkcvv"
      },
      "source": [
        "### **2. ReLU Activation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BmPqwxZklQk"
      },
      "source": [
        "### test_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Scrm7anEksK-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee6961a-e016-4558-d74f-e9a79564ce14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADDITIONAL TEST BATCH\n",
            "Activation: ReLU\n",
            "Learning Rate: 0.001 \n",
            "Test Accuracy of the ReLU model on the 10000 test images: 56.37 %\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "\n",
        "        outputs = model2.forward(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(\"ADDITIONAL TEST BATCH\")\n",
        "    print(f\"Activation: ReLU\")\n",
        "    print(f\"Learning Rate: {learning_rate} \")\n",
        "    print('Test Accuracy of the ReLU model on the 10000 test images: {} %'.format(100 * correct / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W_We5z7lC47"
      },
      "source": [
        "### test_additional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z850YpQZl1zV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "186b96c8-e9c8-4dff-bb68-4f9af8373d65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADDITIONAL TEST BATCH\n",
            "Activation: ReLU\n",
            "Learning Rate: 0.001 \n",
            "Test Accuracy of the ReLU model on the additional test images: 54.32 %\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_add_loader:\n",
        "\n",
        "        outputs = model2.forward(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(\"ADDITIONAL TEST BATCH\")\n",
        "    print(f\"Activation: ReLU\")\n",
        "    print(f\"Learning Rate: {learning_rate} \")\n",
        "    print('Test Accuracy of the ReLU model on the additional test images: {} %'.format(100 * correct / total))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}